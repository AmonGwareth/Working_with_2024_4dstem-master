{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g_klmGpdz7ew"
   },
   "source": [
    "\n",
    "# Fundamentals of 4D-STEM Data Visualization\n",
    "\n",
    "\n",
    "### Microscopy & Microanalysis 2024, Sunday Short Courses\n",
    "### X-10 Guidelines for Performing 4D-STEM Characterization from the Atomic to Micrometer Scales: Experimental Considerations, Data Analysis\n",
    "#### July 28, 2024\n",
    "#### Benjamin H. Savitzky\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dnFWAw-LyBuI"
   },
   "source": [
    "Welcome!\n",
    "\n",
    "Please find below two tutorial Google colab notebooks intended to demonstrate the fundamentals of 4D-STEM data visualization.  To jump right into the colabs, follow the links.  For a quick introductory overview of data visualization for 4D-STEM, please read on...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xY9nqVmrOvXy"
   },
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xjNmpdS8Oyb9"
   },
   "source": [
    "Follow the links below to access the course colab notebook files.\n",
    "\n",
    "- [Example 1:  Virtual imaging a frozen liquid electrolyte](https://colab.research.google.com/drive/1SwxfoiLui3_iiBabetri5AfeYsjRjkT6#scrollTo=wAwx7KShiC8t)\n",
    "- [Example 2:  Virtual imaging, disk detection, and strain in a Si/SiGe superlattice](https://colab.research.google.com/drive/1iNtjf5MntLBopSCS3HJwEpQKXtCmEw7L?usp=drive_link)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j_ZNjoy6itNI"
   },
   "source": [
    "# Visualizating 4D-STEM Data\n",
    "\n",
    "4D-STEM datasets are information rich and there are many ways to slice, process, and display them.  Most will ultimately boil down to collapsing, selecting, or deriving some information to yield an image in 2D.\n",
    "\n",
    "## Getting started\n",
    "\n",
    "### py4DGUI\n",
    "The best place to start in visualizing 4D-STEM data is an interactive GUI - because the data is large and frequently complex,  being able to explore it and look at how the diffraction looks from one position to the next as you move the beam position yourself is essential.  The [py4DSTEM GUI](https://github.com/py4dstem/py4D-browser) is one good option.\n",
    "\n",
    "### Jupyter & Code\n",
    "\n",
    "Once you've gotten a sense of what's in your data, the next question should be: what do you want to know?  Which analyses will help you answer your questions?  Try to decide on the processing you want to do from there.  Running code in a Jupyter notebook is a good middleground between interactively scrolling through scan positions in a GUI and running some large, prebuilt analysis code - you can do more careful, sophisticated analyses then in a GUI, but still have a lot of flexibility to modify, adapt, or build new visualizations or analyses according to your needs.\n",
    "\n",
    "## The Elements of 4D-STEM Data Visualization\n",
    "\n",
    "### Virtual Imaging\n",
    "\n",
    "A virtual image is what we get when we sum up our data along the k-space axes to give us a real-space, image-like object.  With virtual imaging you can recreate the signal you would have gotten if you'd placed a physical detector in the microscope during acquisition of any size and shape you like.  This is very powerful!  You can create annuluar detectors with scattering angles tailored to some properties you only were able to measure after the experiment, create off-axis dark-field images of any Bragg position, or create complex detector functions of almost any kind.  Here we'll limit our attention to *binary* detectors - i.e. each k-space pixel is either included in our detector, or it isn't.  In general our detectors need not be exclusively binary or even real-valued, though binary detectors will be always be fastest.\n",
    "\n",
    "### Virtual Diffraction\n",
    "\n",
    "Virtual diffraction is the reciprocal space mirror of virtual imaging: a virtual diffraction pattern is what we get when we sum up our data along the real space axes to give us a k-space, diffraction-like object.  If virtual imaging is physically analogous to selecting a detector geometry in post-processing, then virtual diffraction is physically analogous to selecting a region of sample to do SAED (selected area electron diffraction) on in post-processing.  That said, they're not quite the same - for instance, when we average a collection of 4D-STEM scan positions we're adding them incoherently, and any coherent beam effects we might see in a parallel beam SAED experiment will be lost.\n",
    "\n",
    "### Calibration\n",
    "\n",
    "Calibration is the most important step of any quantitative analysis.  In these two examples there's only one calibration we'll need to worry about: the position of the origin in diffraction space.  In 4D-STEM, as the beam is rastered over the sample, the optic axis shifts - i.e. the center position of the beam over vacuum moves from one beam position to the next.  We typically call these \"diffraction shifts\"; ideally they wouldn't be present at all, and hardware control can help reduce the size of these shifts, however as a practical matter they'll always be there.  The size of the shifts grows with increasing field-of-view, and depending on FOV and the processing you want to do, you may or may not need to correct for these.  For simplicity these examples have small diffraction shifts; in general, calibrating the origin allows us to correct for the diffraction shifts in both virtual images and virtual diffraction, leading to higher quality data.\n",
    "\n",
    "### Diffraction Grids\n",
    "\n",
    "We'll additionally show one more bit of \"basic\" visualization in this example: tiling diffraction patterns according to the scan position, allowing us to efficiently visually summarize spatial variation of structure in our data.\n",
    "\n",
    "### Bragg detection with Template Matching\n",
    "\n",
    "This tutorial is focused on data visualization, however, we'll touch on detecting Bragg scattering as well.  We'll do so by matching a template, an image of the vacuum beam, to scattered Bragg disk.  If you're interested in learning more about cross-correlative template matching, you can check out the tutorials being taught over in X11 on cryo-STEM image registration, [linked here](https://colab.research.google.com/drive/1wkyEZG6EJcJ-wD39oI1DSPrPzG2zrVB1)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s_7ox5l5QJwx"
   },
   "source": [
    "# Acknowledgements\n",
    "\n",
    "\n",
    "Many thanks to Colin Ophus and David Muller for lead organizing this workshop, and to the rest of the workshop organizing and teaching team including\n",
    "\n",
    "<br>\n",
    "\n",
    "*Cornell University* <br>\n",
    "Steven Zeltmann <br>\n",
    "Dasol Yoon <br>\n",
    "Chia-Hao Lee <br>\n",
    "Hari K.P. <br>\n",
    "\n",
    "<br>\n",
    "\n",
    "*Imperial College London* <br>\n",
    "Geri Torpore <br>\n",
    "\n",
    "<br>\n",
    "\n",
    "*Lawrence Berkeley National Laboratory* <br>\n",
    "Georgios Varnavides <br>\n",
    "Stephanie Ribet <br>\n",
    "\n",
    "<br>\n",
    "\n",
    "Tremendous thanks to the whole py4DSTEM development team which includes, in addition to many of the folks listed above, Harinarayan Krishnan, Arthur McCray, and Matthew Henderson at Lawrence Berkeley Lab.\n",
    "\n",
    "My deepest thanks now and always to Lena Kourkoutis, who guided my career and interests as a scientist starting from well before it began and continuing as long into the future as we continue building on and taking inspiration from her ideas and vision."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
